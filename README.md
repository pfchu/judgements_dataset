# judgements_dataset
We  extract 50,000 court judgments from those where the crime dates are in 2014 and manually annotate the crime information mentioned in the text. We then use this dataset to evaluate the performance of our trained model in predicting crime information. For comparison, we also employ LLama 3.1-70B, an open-source large language model with 70 billion parameters, to predict the crime dates. This comparison allows us to evaluate the strengths and limitations of our model relative to LLama 3.1-70B, offering deeper insights into the effectiveness of each approach in handling domain-specific tasks like crime data extraction. We find that the prediction accuracy of our model is highly consistent with LLama 3.1-70B.


